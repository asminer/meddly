
Interface changes (aside from moving header files around)
======================================================================

Next to implement:
    cardinality
        as a use case for generic operation results :)

Make compute table interface easier to use for simple operations
    (i.e., most of the time)

Updates to operation interface:

    * Add a 'temporary' node handle in unpacked_node,
      will be marked during mark and sweep

    * Allow (back) low-level interface


NEW FILE?

oper_item.h:

    /*
        Idea:
        for unary, binary, etc. operations that operate on,
        or return, something that is NOT a dd_edge.
        For example: cardinality -> long, double, huge integer
        Could have others, e.g., get the first SIZE elements of a set,
        where SIZE could be a huge integer.

        Note:
        NOT used for edge values;
        those are part of a dd_edge.
        These are so we can pass one thing
        (instead of overloading every time)
        to APPLY

        e.g.,
            APPLY(const dd_edge &a, oper_item &result);
            APPLY(const dd_edge &a, const oper_item &b, dd_edge &result);
    */

    enum class oper_item_type {
        ERROR,
        INTEGER,
        LONG,
        DOUBLE,
        HUGEINT
    };

    // for everything other than FOREST
    class oper_item {
        public:
            oper_item(oper_item_type t = ERROR);
            oper_item(int v);
            oper_item(long v);
            oper_item(double v);
#ifdef HAVE_GMP
            oper_item(mpz_t v);
#endif

            // getters for the type

            // getters for the value

            inline void get(int &v) const;
            inline void get(long &v) const;
            inline void get(double &v) const;
#ifdef HAVE_GMP
            inline void get(mpz_t &v) const;
#endif

    //
    // TBD: should we include CT stuff here,
    // i.e., things from ct_object?
    // number of CT slots required
    // how to stuff this into a CT
    // how to extract this from a CT
    // should it be hashed if part of a CT entry?
    //

        private:
            union {
                int         the_int;
                long        the_long;
                double      the_double;
                mpz_t       the_mpz;
            };

            oper_item_type mytype;
    };




unary:

    compute(edge_value inv, node_handle inp,
            int out_level,
            edge_value &outv, node_handle &outp);

    compute(edge_value inv, node_handle inp, long &out);
    compute(edge_value inv, node_handle inp, double &out);
    compute(edge_value inv, node_handle inp, ct_object &out);

    // TBD: do we want a wrapper object for non-dd compute results,
    // something like:
    compute(edge_value inv, node_handle inp, compute_result &out);
    // or can we use ct_object here and expand it???



binary:
    compute(edge_value av, node_handle ap, edge_value bv, node_handle bp,
        int out_level,
        edge_value &outv, node_handle &outp);



Operation updates, to do:
    * re-implement operations using new CT interface
        start with intersection and check timing

    * eventually: remove CTs from operation base class
    * eventually: remove entry registration from operation base class


Unpacked matrix class (new):
    * array of pointers to unpacked_node,
      allocated in chunks of 16
    * memory is recycled like in unpacked_node
    * newUnpacked(forest* f, node_handle p, node_storage_flags rs);
        // p is at an unprimed level
        // rs determines storage for each row
    * newRedundant(const forest* f, int k, const edge_value &ev,
                    node_handle p, node_storage_flags);
    * newIdentity(const forest* f, int k, const edge_value &ev,
                    node_handle p, node_storage_flags);
    * newBlank(forest* f, int k, node_storage_flags);

    * reduce(edge_value &ev, node_handle &p);


Next release:

Finish Reimplementing operations.

Depending on how that goes, maybe adjust the operation hierarchy?

        some thoughts:
            operation
                |
                +--- binary_operation
                        |
                        +---- binary skip levels
                        |           inline void compute_top(
                        |               const dd_edge &a,
                        |               const dd_edge &b, dd_edge c)
                        |
                        |           node_handle compute(node_handle a,
                        |               node_handle b)
                        |
                        +---- binary by levels (for quasi reduced results)
                        |
                        |           node_handle compute(int K,
                        |               node_handle a, node_handle b)
                        |
                        +---- binary, EV, skip levels
                        |
                        |           compute(const edge_value &av,
                        |               node_handle an, const edge_value &,
                        |               node_handle bn, edge_value &ec,
                        |               node_handle &cn)
                        |
                        |           We could use the same iface for MT
                        |           using void edge values, see if there's
                        |           overhead and if so keep them split.
                        |
                        +---- binary, EV, by levels


Although, if we make compute tables easy enough to use, then
the motivation for abstract apply operation implementation goes away.

Ideal:
    class union : public binary_operation {
        // ...
        private:
            ct_entry_type* CTE;
    };

    union::union(owner, fa1, fa2, fres)
        : binary_operation(owner, fa1, fa2, fres)
    {
        CTE = new ct_entry_type("union");
        //        ^
        //        This now also builds the CT (or uses the monolithic one)
        //        for this entry and calls it automatically.
        //        The entry is automatically registered with the CT.
        CTE->setFixed(fa1, fa2);
        CTE->setResult(fres);
    }

    union::~union()
    {
        delete CTE;
        //     ^
        //     unregisters with its CT automatically.
        //     if the CT is not monolithic, it's also destroyed
    }

    void union::compute(node_handle a, node_handle b, node_handle &c)
    {
        if (0==a) return b;
        if (0==b) return a;
        if (1==a) return 1;
        if (1==b) return 1;
        if (a==b) return a; // same forest only

        commute_order(a, b);    // if we can commute, make sure a<b

        ct_vector key(2), result(1);

        key[0].setN(a);
        key[1].setN(b);

        if (CTE->find(key, result)) {
            c = result[0].getN();
            return;
        }

        // do computation with answer stored in c

        result[0].setN(c);
        CTE->addEntry(key, result);
    }

======================================================================

generic EV 'operator' for edges should provide:

    // Combine edge values a and b, store result in c
    static inline void apply(const edge_value &a, const edge_value &b,
        edge_value &c);

    // Combine edge values a and b, store result in a
    static inline void update(edge_value &a, const edge_value &b);

    // "Clear" an edge value; i.e., make it the identity element
    static inline void clear(edge_value &a);

======================================================================
Operations and have they been reimplemented yet
======================================================================
cardinality.cc
        NO      card_mdd_int
        NO      card_mxd_int
        NO      card_mdd_real
        NO      card_mxd_real
        NO      card_mdd_mpz
        NO      card_mxd_mpz

comp_eq.cc
        NO      equal_mdd
        NO      equal_mxd

comp_ge.cc
        NO      moreequal_mdd
        NO      moreequal_mxd

comp_gt.cc
        NO      morethan_mdd
        NO      morethan_mxd

comp_le.cc
        NO      lessequal_mdd
        NO      lessequal_mxd

comp_lt.cc
        NO      lessthan_mdd
        NO      lessthan_mxd

comp_ne.cc
        NO      unequal_mdd
        NO      unequal_mxd

complement.cc
        YES     compl_mdd
        YES     compl_mxd

constrained.cc
        NO      constrained_forwd_dfs_mt
        NO      constrained_bckwd_dfs_mt
        NO      constrained_bckwd_dfs_evplus

copy.cc
        NO      copy_MT_tmpl
        NO      copy_MT2EV
        NO      copy_EV2MT
        NO      copy_EV2EV_fast
        NO      copy_EV2EV_slow

cross.cc
        NO      cross_bool

cycle.cc
        NO      cycle_EV2EV

difference.cc
        YES     diffr_mdd
        YES     diffr_mxd

divide.cc
        NO      divide_mdd
        NO      divide_mxd

intersection.cc
        YES     inter_mdd
        YES     inter_mxd
        NO      inter_max_evplus

maxmin.cc
        NO      maximum_mdd
        NO      maximum_mxd
        NO      minimum_mdd
        NO      minimum_mxd

maxmin_range.cc
        NO      maxrange_int
        NO      maxrange_real
        NO      minrange_int
        NO      minrange_real

mdd2index.cc
        NO      mdd2index_operation

minus.cc
        NO      minus_mdd
        NO      minus_mxd
        NO      minus_evplus
        NO      minus_evtimes

mm_mult.cc
        NO      mm_mult_mt

modulo.cc
        NO      modulo_mdd
        NO      modulo_mxd

multiply.cc
        NO      multiply_mdd
        NO      multiply_mxd
        NO      multiply_evplus
        NO      multiply_evtimes

plus.cc
        NO      plus_mdd
        NO      plus_mxd
        NO      plus_evplus
        NO      plus_evtimes

prepostimage.cc
        NO      mtmatr_mtvect
        NO      mtmatr_evplusvect
        NO      tcXrel_evplus

prepostplus.cc
        NO      preplus_evplus
        NO      postplus_evplus

reach_bfs.cc
        NO      forwd_bfs_mt
        NO      forwd_bfs_evplus
        NO      bckwd_bfs_mt
        NO      bckwd_bfs_evplus

reach_dfs.cc
        NO      forwd_dfs_mt
        NO      forwd_dfs_evplus
        NO      bckwd_dfs_mt

sat_hyb.cc
        NO      forwd_hyb_dfs_by_events_mt

sat_impl.cc
        NO      forwd_impl_dfs_by_events_mt

sat_otf.cc
        NO      forwd_otf_dfs_by_events_mt

sat_pregen.cc
        NO      forwd_dfs_by_events_mt
        NO      bckwd_dfs_by_events_mt

select.cc
        NO      select_MT
        NO      select_EVPlus

transitive_closure.cc
        NO      transitive_closure_forwd_dfs

union.cc
        YES     union_mdd
        YES     union_mxd
        NO      union_min_evplus
        NO      union_min_evplus_mxd

vect_matr.cc
        N/A     VM_evplus_mt
        N/A     MV_evplus_mt

======================================================================


Go through examples/ directory,
see if some stuff can become test cases


Files that need updating / cleanup
------------------------------------------------------------
defines.h
enumerator.h            enumerator.cc
hash_stream.h
heap.h
impl_unique_table.h     impl_unique_table.cc
loggers.h               loggers.cc

relation_node.h         relation_node.cc


======================================================================
Non-critical to do list (side quests)
======================================================================
* Minterm collections, unioning with existing sets
    full / sparse minterms
    sets / relations

* Evaluation by overloading() on dd_edge?
    Using a single minterm? Or vector of integers?

* Enumeration
    Tie to evaluation?
    Have 'fixed' variables and 'free' variables
        all fixed: evaluation
        all free:  old enumeration
        primed / unprimed are fixed: like old row / col enumerators

    Fixed levels: use full unpacked
    Free levels : use sparse unpacked

* Creating functions for variables
    also functions of single variables
    currently in forest, does it belong there?
    maybe goes with sparse minterm collections?

* all different operation
    intersect a function with 'this set of vars
    must be all different`.
    Limit to possible values {0, ..., 31} so we can
    use unsigned ints for the set of taken values?

* existential quantification operation
    boolean only? or describe as "max value over these vars"?

* universal quantification operation
    boolean only? or describe as "min value over these vars"?

* interval decision diagrams?

* look at using ev* over rationals to avoid floating-point issues?

